<!doctype html>
<html>

<head>
	<meta charset="utf-8">
	<meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no">

	<title>Interlinking RDF-based datasets: A structure-based approach</title>

	<link rel="stylesheet" href="css/reset.css">
	<link rel="stylesheet" href="css/reveal.css">
	<link rel="stylesheet" href="css/theme/black.css">

	<!-- Theme used for syntax highlighting of code -->
	<link rel="stylesheet" href="lib/css/monokai.css">

	<!-- Printing and PDF exports -->
	<script>
		var link = document.createElement('link');
		link.rel = 'stylesheet';
		link.type = 'text/css';
		link.href = window.location.search.match(/print-pdf/gi) ? 'css/print/pdf.css' : 'css/print/paper.css';
		document.getElementsByTagName('head')[0].appendChild(link);
	</script>
</head>

<body>
	<div class="reveal">
		<div class="slides">
			<section>
				<h2>Interlinking RDF-based datasets:</h2>
				<h3>A structure-based approach</h3>
				<p>
					<small>Pierre-Henri Paris, Fayçal Hamdi, Samira Si-said Cherfi</small>
				</p>
				<img data-src="img/cnam.png" alt="Cnam">
				<img data-src="img/sorbonne.png" alt="Sorbonne Université">
				<!-- <aside class="notes">
					Mettre l'accent sur la deuxième partie de l'approche qui est la plus
					grande contribution.
				</aside> -->
				<aside class="notes">
					<ul>
						<li>Travail réalisé au sein de l'équipe ISID du laboratoire CEDRIC au Cnam</li>
						<li>Avec S Si-Said Cherfi et F Hamdi</li>
						<li>Il s'agit d'une approche permettant d'interconnecter des jeux de données au format RDF
							en utilisant la structure de ce jeux de données.
						</li>
					</ul>
				</aside>
			</section>
			<section>
				<h3>Instance matching</h3>
				<!-- <h3>Instance matching is about two main aspects:</h3> -->
				<h5>What?</h5>
				<ul>
					<li>Linking instances together</li>
					<li>Specifying identical instances (owl:sameAs links)</li>
					<li>Interlink datasets</li>
				</ul>
				<div class="fragment">
					<h5>Why?</h5>
					<ul>
						<li>Discover new knowledge (indiscernibility of identicals)</li>
						<li>Data integration</li>
					</ul>
				</div>
				<aside class="notes">
					<ol>
						<li>Qu'est-ce que l'appariement d'instances ? Il s'agit de lié des instances ensembles
							et plus précisément de trouver des liens d'identité entre instances lorsqu'on utilise
							la propriété owl:sameAs. Cela permet aussi de lier des jeux de données entre eux.
						</li>
						<li>Pourquoi veut-on lier des données entre elles ? Tout d'abord pour découvrir de nouvelles
							connaissances. En effet le 4ème principe des données liées proposé par Tim Berners-Lee
							consiste à lier les instances entre elles pour pouvoir passer d'un jeu
							de données à un autre. Quand ces liens sont des type owl:sameAs, on bénéficie alors de
							sa sémantique et de l'indiscernabilité des identiques.
						</li>
					</ol>
				</aside>
			</section>
			<!-- <section>
				<h3>Instance matching is about two main aspects:</h3>
				<ul>
					<li>Linking instances together</li>
					<li>Specifying identical instances</li>
				</ul>
				<ul>
					<li>discover new things (4th principle of Linked Data)</li>
					<li>Many different properties can be used</li>
				</ul>
				<h5>owl:sameAs</h5>
				<ul>
					<li>Increase completeness</li>
					<li>Reduce the gap due to lack of IRI being reused</li>
					<li>...</li>
				</ul>
				<footer style="font-size: medium">https://www.w3.org/DesignIssues/LinkedData.html</footer>
				<aside class="notes">
					<ol></ol>
				</aside>
			</section> -->
			<!-- <section>why it is important?</section> -->
			<section>
				<h3>Related work</h3>
				<h5>Legato</h5>
				<img data-src="img/legato.png" alt="legato">
				<aside class="notes">
					<ol>
						<li>Repérage des propriétés dites problématiques comme les commentaires</li>
						<li>Création de descriptions à l'aide des propriétés littérales</li>
						<li>Pour chaque description, les termes sont tokenizés et pondéré avec leur TF-IDF
							(term frequency-inverse document frequency), puis projetées dans un espace vectoriel.
							Lors de la phase de pre-matching, c'est la similarité cosinus qui est utilisée pour apparier
							les vecteurs entre eux.</li>
						<li>
							La dernière phase de réparation sert à vérifier que les liens trouvés sont correctes et donc
							à diminuer les faux positifs (et augmenter la précision). Ici c'est un algorithme de
							clustering qui est utilisé pour
							créer des groupes d'instances au sein d'un jeu de données. Ensuite, pour deux groupes
							similaires appartenant chacun à un jeu de données ils essaient de trouver une propriété
							servant de clé et classe les couples en fonction de cette clé et utilise au cas ou plusieurs
							candidats sont possibles ceui qui a la similarité la plus forte.
						</li>
					</ol>
				</aside>
			</section>
			<section>
				<h3>Related work</h3>
				<h5>Logmap</h5>
				<img data-src="img/logmap.png" alt="logmap">
				<aside class="notes">
					<ol>
						<li>Récupération des littéraux de chaque instance. Avec une base de connaissances externes, les
							synonymes aussi sont récupérés.
							<!--TODO: compléter les 2 parties d'indexations-->
						</li>
					</ol>
				</aside>
			</section>
			<section>
				<h3>Related work</h3>
				<h5>I-Match</h5>
				<img data-src="img/imatch.png" alt="imatch">
				<aside class="notes">
					<ol>
						<li>
							Comme pour Legato, pour chaque instance sont extrait les littéraux. Ces littéraux sont
							ensuite normalisés à l'aide de techniques de NLP (minuscule, Lemmatisation et Stemming)
						</li>
						<li>Distance d'édition pour l'appariement de chaînes de caractères</li>
						<li>Sélection du candidat qui a le plus haut score de correspondance</li>
					</ol>
				</aside>
			</section>
			<!-- <section>
				<section>
					<h3>Related work</h3>
					<ul>
						<li class="fragment">Instance matching</li>
						<li class="fragment">Identity link assessment</li>
					</ul>
				</section>
				<section>
					<h4>Instance matching</h4>
					<ul>
						<li>similarity between normalized strings (Khiat and Mackeprang [12])</li>
						<li>embedding (Achichi et al. [2])</li>
						<li>repairing module (Jiménez-Ruiz and Grau [11],)</li>
						<li>etc</li>
					</ul>
				</section>
				<section>
					<h4>Identity link assessment</h4>
					<ul>
						<li>network measures (Guéret et al. [7] and Idrissou et al. [10])</li>
						<li>unique name assumption (De Melo [5])</li>
						<li>logic through semantic features (Papaleo et al. [15])</li>
						<li>data mining (Paulheim [16])</li>
						<li>semantics and graph partitioning (Valdestilhas et al. [18])</li>
						<li>community detection (Raad et al. [17])</li>
					</ul>
				</section>
			</section> -->
			<section>
				<h3>Approach</h3>
				<ul>
					<li>Direct semantic proof</li>
					<li>The use of properties</li>
				</ul>
			</section>
			<section>
				<h3>Approach</h3>
				<h5>Direct semantic proof</h5>
				<ul>
					<li>sameAs transitivity</li>
					<li>functional properties</li>
					<li>maximum cardinality of properties</li>
					<li>etc.</li>
				</ul>
				<blockquote class="fragment">
					<h6>Example</h6>
					<span style="font-weight: bolder">If</span> p is a functional property, (x, p, y1) and (x, p,
					y2)
					<br>
					<span style="font-weight: bolder">then</span> (y1, owl:sameAs, y2)
					<!-- &ldquo;For years there has been a theory that millions of monkeys typing at random on millions of typewriters would
					reproduce the entire works of Shakespeare. The Internet has proven this theory to be untrue.&rdquo; -->
				</blockquote>
				<aside class="notes">
					De manière assez simple, on cherche une preuve sémantique directe d'un lien owl:sameAs entre les
					deux instantes.
					Cad, que pour deux instances données, on va regarder si une règle sémantique permettant soit de
					déduire un lien sameAs, soit un lien differentFrom existe.
				</aside>
			</section>
			<section>
				<h3>Approach</h3>
				<h5>The use of properties</h5>
				<!-- TODO: -->
				<aside class="notes">
				</aside>
			</section>
			<section>
				<h3>Experiments</h3>
				<h5>DBpedia and Wikidata</h5>
				<div>
					Our <strong>goal</strong> is to evaluate our approach on real-world data
				</div>
			</section>
			<section>
				<h3>Experiments</h3>
				<h5>DBpedia and Wikidata</h5>
				<!-- <div class="fragment fade-in-then-out">
				</div> -->
				<ul>
					<li>From DBpedia, selection of 36 people each having at least 15 homonyms in Wikidata</li>
					<li>Source KB contains 277 instances, 3468 triples and 36 candidate instances</li>
					<li>Target KB contains 1170 instances, 7667 triples and 552 candidate instances</li>
					<li>All owl:sameAs links removed and saved as gold standard</li>
				</ul>
			</section>
			<section>
				<h3>Experiments</h3>
				<h5>DBpedia and Wikidata</h5>
				<table>
					<thead>
						<tr>
							<th>True positive</th>
							<th>False positive</th>
							<th>False Negative</th>
							<th>Precision</th>
							<th>Recall</th>
							<th>F-Measure</th>
						</tr>
					</thead>
					<tbody>
						<tr>
							<td>33</td>
							<td>3</td>
							<td>3</td>
							<td>0.917</td>
							<td>0.917</td>
							<td>0.917</td>
						</tr>
					</tbody>
				</table>
				<ul>
					<li>The 3 false positives are the same than the false negatives</li>
					<li>Each times the right candidates was the second one</li>
					<!-- TODO: dire en quoi c'est bien ou pas -->
				</ul>
				<!-- <p class="fragment">91.7% for precision and recall</p> -->
			</section>
			<section>
				<h3>Experiments</h3>
				<h5>OAEI 2017</h5>
				<div>
					Our <strong>goal</strong> is to compare our approach against state of the art approaches that use
					NLP techniques.
				</div>
			</section>
			<section>
				<h3>Experiments</h3>
				<h5>OAEI 2017</h5>
				<ul>
					<li>SPIMBENCH SANDBOX: alterations of an original one
						through value-based, structure-based, and semantics-aware transformations</li>
					<li>Source KB contains 1432 instances,
						10883 triples and 349 candidate instances</li>
					<li>Target KB
						contains 1453 instances, 10868 triples and 443 candidate instances</li>
				</ul>
			</section>
			<section>
				<h3>Experiments</h3>
				<h5>OAEI 2017</h5>
				<table>
					<thead>
						<tr>
							<th>Participants</th>
							<th>Precision</th>
							<th>Recall</th>
							<th>F-Measure</th>
						</tr>
					</thead>
					<tbody>
						<tr>
							<td>AML</td>
							<td>0.849</td>
							<td><span style="color:#dc6414">1.000</span></td>
							<td>0.918</td>
						</tr>
						<tr>
							<td>I-Match</td>
							<td>0.854</td>
							<td>0.997</td>
							<td><span style="color:#dc6414">0.920</span></td>
						</tr>
						<tr>
							<td>Legato</td>
							<td><span style="color:#dc6414">0.980</span></td>
							<td>0.730</td>
							<td>0.840</td>
						</tr>
						<tr>
							<td>LogMap</td>
							<td>0.938</td>
							<td>0.763</td>
							<td>0.841</td>
						</tr>
						<tr>
							<td><span style="color:#dc6414">Our approach</span></td>
							<td>0.854</td>
							<td>0.996</td>
							<td><span style="color:#dc6414">0.920</span></td>
						</tr>
					</tbody>
				</table>
				<aside class="notes">
					<!-- TODO: expliquer les résultas -->
				</aside>
			</section>
			<section>
				<h3>Experiments</h3>
				<h5>OAEI 2017</h5>
				<ul>
					<!-- TODO: dire en quoi c'est bien ou pas, décrire les résultats, force et faiblesses -->
				</ul>
			</section>
			<section>
				<h3>Conclusion</h3>
				<ul>
					<li>Fully automatized instance matching approach</li>
					<li class="fragment">Based on semantics and usage of properties</li>
					<li class="fragment">Recall is good</li>
					<li class="fragment">Lack of false positive detection</li>
				</ul>
				<footer style="font-size: medium">https://github.com/PHParis/im_prototype</footer>
			</section>
		</div>
	</div>

	<script src="js/reveal.js"></script>

	<script>
		// More info about config & dependencies:
		// - https://github.com/hakimel/reveal.js#configuration
		// - https://github.com/hakimel/reveal.js#dependencies
		Reveal.initialize({
			dependencies: [{
					src: 'plugin/markdown/marked.js'
				},
				{
					src: 'plugin/markdown/markdown.js'
				},
				{
					src: 'plugin/notes/notes.js',
					async: true
				},
				{
					src: 'plugin/highlight/highlight.js',
					async: true
				}
			]
		});
	</script>
</body>

</html>