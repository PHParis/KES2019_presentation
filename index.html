<!doctype html>
<html>

<head>
	<meta charset="utf-8">
	<meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no">

	<title>Interlinking RDF-based datasets: A structure-based approach</title>

	<link rel="stylesheet" href="css/reset.css">
	<link rel="stylesheet" href="css/reveal.css">
	<link rel="stylesheet" href="css/theme/black.css">

	<!-- Theme used for syntax highlighting of code -->
	<link rel="stylesheet" href="lib/css/monokai.css">

	<!-- Printing and PDF exports -->
	<script>
		var link = document.createElement('link');
		link.rel = 'stylesheet';
		link.type = 'text/css';
		link.href = window.location.search.match(/print-pdf/gi) ? 'css/print/pdf.css' : 'css/print/paper.css';
		document.getElementsByTagName('head')[0].appendChild(link);
	</script>
</head>

<body>
	<div class="reveal">
		<div class="slides">
			<section>
				<h2>Interlinking RDF-based datasets:</h2>
				<h3>A structure-based approach</h3>
				<p>
					<small>Pierre-Henri Paris, Fayçal Hamdi, Samira Si-Said Cherfi</small>
				</p>
				<img data-src="img/cnam.png" alt="Cnam">
				<img data-src="img/sorbonne.png" alt="Sorbonne Université">
				<!-- <aside class="notes">
					Mettre l'accent sur la deuxième partie de l'approche qui est la plus
					grande contribution.
				</aside> -->
				<aside class="notes">
					<ul>
						<li>Travail réalisé au sein de l'équipe ISID du laboratoire CEDRIC au Cnam</li>
						<li>Avec S Si-Said Cherfi et F Hamdi</li>
						<li>Il s'agit d'une approche permettant d'interconnecter des jeux de données au format RDF
							en utilisant la structure de ce jeux de données.
						</li>
					</ul>
				</aside>
			</section>
			<section>
				<h3>Instance matching</h3>
				<!-- <h3>Instance matching is about two main aspects:</h3> -->
				<h5>What?</h5>
				<ul>
					<li>Linking instances together</li>
					<li>Specifying identical instances (owl:sameAs links)</li>
					<li>Interlink datasets</li>
				</ul>
				<div class="fragment">
					<h5>Why?</h5>
					<ul>
						<li>Discover new knowledge (indiscernibility of identicals)</li>
						<li>Data integration</li>
						<li>etc.</li>
					</ul>
				</div>
				<aside class="notes">
					<ol>
						<li>Appariement d'instances</li>
						<li>Qu'est-ce que l'appariement d'instances ? Il s'agit de lié des instances ensembles
							et plus précisément de trouver des liens d'identité entre instances lorsqu'on utilise
							la propriété owl:sameAs. Cela permet aussi de lier des jeux de données entre eux.
						</li>
						<li>Pourquoi veut-on lier des données entre elles ? Tout d'abord pour découvrir de nouvelles
							connaissances. En effet le 4ème principe des données liées proposé par Tim Berners-Lee
							consiste à lier les instances entre elles pour pouvoir passer d'un jeu
							de données à un autre. Quand ces liens sont des type owl:sameAs, on bénéficie alors de
							sa sémantique et de l'indiscernabilité des identiques.
						</li>
					</ol>
				</aside>
			</section>
			<!-- <section>
				<h3>Instance matching is about two main aspects:</h3>
				<ul>
					<li>Linking instances together</li>
					<li>Specifying identical instances</li>
				</ul>
				<ul>
					<li>discover new things (4th principle of Linked Data)</li>
					<li>Many different properties can be used</li>
				</ul>
				<h5>owl:sameAs</h5>
				<ul>
					<li>Increase completeness</li>
					<li>Reduce the gap due to lack of IRI being reused</li>
					<li>...</li>
				</ul>
				<footer style="font-size: medium">https://www.w3.org/DesignIssues/LinkedData.html</footer>
				<aside class="notes">
					<ol></ol>
				</aside>
			</section> -->
			<!-- <section>why it is important?</section> -->
			<section>
				<h3>Related work</h3>
				<h5>Legato</h5>
				<img data-src="img/legato.png" alt="legato">
				<aside class="notes">
					<ol>
						<li>Repérage des propriétés dites problématiques comme les commentaires</li>
						<li>Création de descriptions à l'aide des propriétés littérales</li>
						<li>Pour chaque description, les termes sont tokenizés et pondéré avec leur TF-IDF
							(term frequency-inverse document frequency), puis projetées dans un espace vectoriel.
							Lors de la phase de pre-matching, c'est la similarité cosinus qui est utilisée pour apparier
							les vecteurs entre eux.</li>
						<li>
							La dernière phase de réparation sert à vérifier que les liens trouvés sont correctes et donc
							à diminuer les faux positifs (et augmenter la précision). Ici c'est un algorithme de
							clustering qui est utilisé pour
							créer des groupes d'instances au sein d'un jeu de données. Ensuite, pour deux groupes
							similaires appartenant chacun à un jeu de données ils essaient de trouver une propriété
							servant de clé et classe les couples en fonction de cette clé et utilise au cas ou plusieurs
							candidats sont possibles ceui qui a la similarité la plus forte.
						</li>
					</ol>
				</aside>
			</section>
			<!-- <section>
				<h3>Related work</h3>
				<h5>Logmap</h5>
				<img data-src="img/logmap.png" alt="logmap">
				<aside class="notes">
					<ol>
						<li>Récupération des littéraux de chaque instance. Avec une base de connaissances externes, les
							synonymes aussi sont récupérés.
							TODO: compléter les 2 parties d'indexations
						</li>
					</ol>
				</aside>
			</section> -->
			<section>
				<h3>Related work</h3>
				<h5>I-Match</h5>
				<img data-src="img/imatch.png" alt="imatch">
				<aside class="notes">
					<ol>
						<li>
							Comme pour Legato, pour chaque instance sont extrait les littéraux. Ces littéraux sont
							ensuite normalisés à l'aide de techniques de NLP (minuscule, Lemmatisation et Stemming)
						</li>
						<li>Distance d'édition pour l'appariement de chaînes de caractères</li>
						<li>Sélection du candidat qui a le plus haut score de correspondance!</li>
					</ol>
				</aside>
			</section>
			<!-- <section>
				<section>
					<h3>Related work</h3>
					<ul>
						<li class="fragment">Instance matching</li>
						<li class="fragment">Identity link assessment</li>
					</ul>
				</section>
				<section>
					<h4>Instance matching</h4>
					<ul>
						<li>similarity between normalized strings (Khiat and Mackeprang [12])</li>
						<li>embedding (Achichi et al. [2])</li>
						<li>repairing module (Jiménez-Ruiz and Grau [11],)</li>
						<li>etc</li>
					</ul>
				</section>
				<section>
					<h4>Identity link assessment</h4>
					<ul>
						<li>network measures (Guéret et al. [7] and Idrissou et al. [10])</li>
						<li>unique name assumption (De Melo [5])</li>
						<li>logic through semantic features (Papaleo et al. [15])</li>
						<li>data mining (Paulheim [16])</li>
						<li>semantics and graph partitioning (Valdestilhas et al. [18])</li>
						<li>community detection (Raad et al. [17])</li>
					</ul>
				</section>
			</section> -->
			<section>
				<h3>Approach</h3>
				<ul>
					<li>Direct semantic proof</li>
					<li>The use of properties</li>
				</ul>
			</section>
			<section>
				<h3>Approach</h3>
				<h5>Direct semantic proof</h5>
				<ul>
					<li>Functional properties</li>
					<li>Maximum cardinality of properties</li>
					<li>etc.</li>
				</ul>
				<blockquote class="fragment" style="font-size: xx-large">
					<h6>Example</h6>
					<span style="font-weight: bolder">If</span> hasFather is a functional property, (:John, hasFather,
					ns1:Bill) and (:John, hasFather,
					ns2:William)
					<br>
					<span style="font-weight: bolder">then</span> (ns1:Bill, owl:sameAs, ns2:William)
					<!-- &ldquo;For years there has been a theory that millions of monkeys typing at random on millions of typewriters would
					reproduce the entire works of Shakespeare. The Internet has proven this theory to be untrue.&rdquo; -->
				</blockquote>
				<aside class="notes">
					De manière assez simple, on cherche une preuve sémantique directe d'un lien owl:sameAs entre les
					deux instantes.
					Cad, que pour deux instances données, on va regarder si une règle sémantique permettant soit de
					déduire un lien sameAs, soit un lien differentFrom existe.
				</aside>
			</section>
			<section>
				<h3>Approach</h3>
				<h5>The use of properties</h5>
				<p style="text-align: left">First intuition (weight of a role):</p>
				<p style="text-align: left">If 90% of the People’s instances use the role <span
						style="font-style: italic">name</span> but only 8% of those instances use the role <span
						style="font-style: italic">ownerOf</span>,
					then <span style="font-style: italic">ownerOf</span> might help more to determine (the absence of)
					an identity relation between two instances.</p>
				<aside class="notes">
				</aside>
			</section>
			<section>
				<h3>Approach</h3>
				<h5>The use of properties</h5>
				<p style="text-align: left">Second intuition (discriminating power of a role-value pair):</p>
				<p style="text-align: left">If we have 100 instances with the role-value &lt;town, Paris&gt; but only 3
					instances with the role-value
					&lt;town, Peyrabout&gt;, then the couple &lt;town, Peyrabout&gt; helps to discriminate more
					instances.
					<aside class="notes">
					</aside>
			</section>
			<section>
				<h3>Approach</h3>
				<h5>The use of properties</h5>
				<p style="text-align: left">Weight of evidence:</p>
				<p style="text-align: left">If x1, x2 and x3 are three instances where x1 is from the source KB and x2
					and x3 are from the target KB. If
					we have four evidences between x1 and x2, and eight evidences between x1 and x3 then
					<span style="color:#dc6414">we give a bonus to the comparison with the more evidences to
						present</span>.</p>
				<aside class="notes">
				</aside>
			</section>
			<section>
				<h3>Approach</h3>
				<h5>The use of properties</h5>
				<p style="text-align: left">Depth of a concept:</p>
				<p style="text-align: left">If $\mathcal{KB}=dbo$
					then $depth_{dbo}(Agent)=1$ and $depth_{dbo}(Biologist)=4$ since $Agent$ is a direct sub concept of
					$owl{:}Thing$
					and $Biologist\sqsubseteq Scientist\sqsubseteq Person\sqsubseteq Agent\sqsubseteq owl{:}Thing$.</p>
				<aside class="notes">
				</aside>
			</section>
			<section>
				<h3>Approach</h3>
				<h5>Main algorithm</h5>
				<pre><code class="Python" data-line-numbers>if IsSemProof(x1, x2): 
  return SemProofValue(x1, x2)
scores = []
C = deepest common concept between x1 and x2
for R in {common roles between x1 and x2}:
  (maxSim, o) = max(R, x1, x2)
  subscore = Aggregation_1(
     maxSim,
     (1 - WKBs(R, C)),
     (1 - DKBs(C, R, o)))
  scores.append(subscore)
return Aggregation_2(weight of evidence, scores)
</code></pre>
				<aside class="notes">
				</aside>
			</section>
			<section>
				<h3>Experiments</h3>
				<h5>DBpedia and Wikidata</h5>
				<div>
					Our <strong>goal</strong> is to evaluate our approach on real-world datasets.
				</div>
			</section>
			<section>
				<h3>Experiments</h3>
				<h5>DBpedia and Wikidata</h5>
				<!-- <div class="fragment fade-in-then-out">
				</div> -->
				<div>Construction of source and target KBs</div>
				<ul>
					<li>DBpedia 2016-10 and DBpedia-Wikidata 03.30.2015</li>
					<li>From DBpedia, <span style="color:#dc6414">selection of 36 people</span> each having <span
							style="color:#dc6414">at least 15 homonyms</span> in Wikidata (rdfs:label)
					</li>
					<li>Source KB contains all statements having one of this 36 people in subject or object</li>
					<li>Target KB contains all statements having one of this homonyms in subject or object</li>
				</ul>
			</section>
			<section>
				<h3>Experiments</h3>
				<h5>DBpedia and Wikidata</h5>
				<table>
					<thead>
						<tr>
							<th>True positive</th>
							<th>False positive</th>
							<th>False Negative</th>
							<th>Precision</th>
							<th>Recall</th>
							<th>F-Measure</th>
						</tr>
					</thead>
					<tbody>
						<tr>
							<td>33</td>
							<td>3</td>
							<td>3</td>
							<td>0.917</td>
							<td>0.917</td>
							<td>0.917</td>
						</tr>
					</tbody>
				</table>
				<ul>
					<li>The 3 false positives are the same than the false negatives</li>
					<li>Each times the right candidates was the second one</li>
					<!-- TODO: dire en quoi c'est bien ou pas -->
				</ul>
				<!-- <p class="fragment">91.7% for precision and recall</p> -->
			</section>
			<section>
				<h3>Experiments</h3>
				<h5>OAEI 2017</h5>
				<div>
					Our <strong>goal</strong> is to compare our approach against state of the art approaches that use
					NLP techniques.
				</div>
			</section>
			<section>
				<h3>Experiments</h3>
				<h5>OAEI 2017</h5>
				SPIMBENCH SANDBOX: alterations of an original one
				through value-based, structure-based, and semantics-aware transformations
			</section>
			<section>
				<h3>Experiments</h3>
				<h5>OAEI 2017</h5>
				<table>
					<thead>
						<tr>
							<th>Participants</th>
							<th>Precision</th>
							<th>Recall</th>
							<th>F-Measure</th>
						</tr>
					</thead>
					<tbody>
						<tr>
							<td>AML</td>
							<td>0.849</td>
							<td><span style="color:#dc6414">1.000</span></td>
							<td>0.918</td>
						</tr>
						<tr>
							<td>I-Match</td>
							<td>0.854</td>
							<td>0.997</td>
							<td><span style="color:#dc6414">0.920</span></td>
						</tr>
						<tr>
							<td>Legato</td>
							<td><span style="color:#dc6414">0.980</span></td>
							<td>0.730</td>
							<td>0.840</td>
						</tr>
						<tr>
							<td>LogMap</td>
							<td>0.938</td>
							<td>0.763</td>
							<td>0.841</td>
						</tr>
						<tr>
							<td><span style="color:#dc6414">Our approach</span></td>
							<td>0.854</td>
							<td>0.996</td>
							<td><span style="color:#dc6414">0.920</span></td>
						</tr>
					</tbody>
				</table>
				<aside class="notes">
				</aside>
			</section>
			<section>
				<h3>Experiments</h3>
				<h5>OAEI 2017</h5>
				<ul>
					<!-- TODO: dire en quoi c'est bien ou pas, décrire les résultats, force et faiblesses -->
					<li>Wrong candidate selection with very similar instances</li>
					<li>Arithmetic mean</li>
					<li>Use both KBs</li>
				</ul>
			</section>
			<section>
				<h3>Conclusion</h3>
				<ul>
					<li>Fully automatized instance matching approach</li>
					<li class="fragment">Based on semantics and usage of properties</li>
					<li class="fragment">Recall is good</li>
					<li class="fragment">Lack of false positive detection/correction</li>
					<li class="fragment">Explore other ways to aggregate the different scores</li>
					<li class="fragment">Refine linkset we produced to have fewer false positives results</li>
				</ul>
				<!-- <ul>
					<li>Explore other ways to aggregate the different scores</li>
					<li>Refine linkset we produced to have fewer false positives results</li>
				</ul> -->
				<footer style="font-size: medium">https://github.com/PHParis/im_prototype</footer>
			</section>
			<section>
				<h3>Experiments</h3>
				<h5>DBpedia and Wikidata</h5>
				<!-- <div class="fragment fade-in-then-out">
				</div> -->
				<ul>
					<li>Source KB contains 277 instances, 3468 triples and 36 candidate instances</li>
					<li>Target KB contains 1170 instances, 7667 triples and 552 candidate instances</li>
					<li>All owl:sameAs links removed and saved as gold standard</li>
				</ul>
			</section>
			<section>
				<h3>Experiments</h3>
				<h5>OAEI 2017</h5>
				<ul>
					<li>Source KB contains 1432 instances,
						10883 triples and 349 candidate instances</li>
					<li>Target KB
						contains 1453 instances, 10868 triples and 443 candidate instances</li>
					<li>Gold standard provided</li>
				</ul>
			</section>
			<section>
				<h6>Weight of a role</h6>
				<p>$W_{\mathcal{KB}}(R,C)=\frac{NS_{\mathcal{KB}}(C,R)}{NS_{\mathcal{KB}}(C)}$ and
					$W_{\mathcal{KB}}(R,C)\in [0,1]$</p>
			</section>
			<section>
				<h6>Discriminating power</h6>
				<p>$D_{\mathcal{KB}}(C,R,o)=\frac{NS_{\mathcal{KB}}(C,R,o)}{NS_{\mathcal{KB}}(C,R)}$ and
					$D_{\mathcal{KB}}(C,R,o)\in [0,1]$</p>
			</section>
			<section>
				<h6>Weight of an evidence</h6>
				<p>$\frac{\mid R_{x_1}\cap R_{x_2}\mid}{\mid R_{x_1}\mid +\mid R_{x_2}\mid -
					\mid R_{x_1}\cap R_{x_2}\mid}$, where $evidence\in [0,1]$</p>
			</section>
		</div>
	</div>

	<script src="js/reveal.js"></script>

	<script>
		// More info about config & dependencies:
		// - https://github.com/hakimel/reveal.js#configuration
		// - https://github.com/hakimel/reveal.js#dependencies
		Reveal.initialize({
			math: {
				mathjax: 'plugin/math/MathJax-master/MathJax.js', //'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js',
				config: 'TeX-AMS_HTML-full' // See http://docs.mathjax.org/en/latest/config-files.html
				// pass other options into `MathJax.Hub.Config()`
				// TeX: { Macros: macros }
			},
			dependencies: [{
					src: 'plugin/markdown/marked.js'
				},
				{
					src: 'plugin/markdown/markdown.js'
				},
				{
					src: 'plugin/notes/notes.js',
					async: true
				},
				{
					src: 'plugin/highlight/highlight.js',
					async: true
				},
				{
					src: 'plugin/math/math.js',
					async: true
				}
			]
		});
		Reveal.configure({
			slideNumber: true
		});
	</script>
</body>

</html>